#include <gst/gst.h>
#include <gst/app/gstappsrc.h>
#include <gst/app/gstappsink.h>
#include <stdio.h>
#include <string.h>
#include <unistd.h>
#include <stdlib.h>
#include <fcntl.h>
#include <linux/fb.h>
#include <sys/mman.h>
#include <sys/ioctl.h>
#include <signal.h>


#include <sys/types.h>
#include <sys/stat.h>
#include <sys/time.h>
#include <sys/mman.h>
#include <fcntl.h>
#include <assert.h>
#include <pthread.h>
#include <errno.h>
#include <math.h>

#include <X11/Xlib.h>
#include <X11/Xutil.h>


#define AUTO

typedef struct _GstDataStruct{
    GstElement *pipeline;
    GstElement *app_source;
    GstElement *video_convert;
    GstElement *auto_video_convert;
    GstElement *h264_encoder;
    GstElement *jpgenc;
    GstElement *mp4mux;
    GstElement *file_sink;
    GstElement *app_sink;
    guint sourceid;        /* To control the GSource */
    guint app_src_index;
    guint app_sink_index;
    GMainLoop *loop;  /* GLib's Main Loop */
} GstDataStruct;
 

static FILE *fp;            // 打开或保存文件的的指针
static GstBus *bus;
static GstDataStruct GstData;

static  int screen_width;
static  int screen_height;
static  int frame_rate;
static 	unsigned char *g_rgb_buffer = NULL;
static 	Window desktop;
static 	Display* dsp;



static void new_h264_sample_on_appsink (GstElement *sink, GstDataStruct *pGstData);
static void eos_on_appsink (GstElement *sink, GstDataStruct *pGstData);
static gboolean read_data(GstDataStruct *pGstData);
static void start_feed (GstElement * pipeline, guint size, GstDataStruct *pGstData);
static void stop_feed (GstElement * pipeline, GstDataStruct *pGstData);
gboolean bus_msg_call(GstBus *bus, GstMessage *msg, GstDataStruct *pGstData);
static gboolean rj_link_elements_with_filter (GstElement *element1, GstElement *element2);
static int xDispalyInit();

static gboolean
f_link_elements_with_filter (GstElement *element1, GstElement *element2)
{
  gboolean link_ok;
  GstCaps *caps;


  caps = gst_caps_new_simple("video/x-raw",
                "width", G_TYPE_INT, screen_width,
                "height", G_TYPE_INT, screen_height,
                "framerate",GST_TYPE_FRACTION, frame_rate, 1, NULL);


  link_ok = gst_element_link_filtered (element1, element2, caps);
  gst_caps_unref (caps);


  if (!link_ok) {
    g_warning ("Failed to link element1 and element2!");
  }


  return link_ok;
}


int main(int argc, char *argv[])
{
    guint bus_watch_id;
    char file_name[32];
    char output_file_name[32];
    frame_rate = 30;
    
    if(argc == 2)
    {
        frame_rate = atoi(argv[1]);
        printf("use user new define frame_rate:%d \n", frame_rate);
        
    }
#if 0
    memset (output_file_name, 0, sizeof(output_file_name));
    sprintf(output_file_name,"ximagesrc_out_%d.h264",frame_rate);
    printf("auto_demo_2 output file name is :%s\n", output_file_name);
#else
    memset (file_name, 0, sizeof(file_name));
    sprintf(file_name,"appsrc_out_%d.h264",frame_rate);
    printf("user_demo_1 output file name is :%s\n", file_name);
#endif
    
    fp = fopen(file_name, "wb");
    if(!fp)
    {
        printf("can not open file %s", file_name);
        return -1;
    }

	int ret = 0;
	ret = xDispalyInit();
	if (ret < 0) {
	    printf("xDispalyInit exe failed !\n");
		return -1;
	}
    printf("screen_width:%d screen_height:%d\n", screen_width, screen_height);
	g_rgb_buffer = (unsigned char *)malloc(screen_width * screen_height * 4); 
    
    
    /* Initialize cumstom data structure */
    printf("============= gst init start ============\n");
    memset (&GstData, 0, sizeof (GstDataStruct));
    gst_init (&argc, &argv);
    
    /* Create gstreamer elements */
    GstElementFactory *factory;
    GstElement * element;
    GstData.pipeline = gst_pipeline_new ("encode_test");
    
#ifdef AUTO
    GstData.app_source = gst_element_factory_make ("ximagesrc","video-source");
/*
    // create filesink element /
    factory = gst_element_factory_find ("filesink");
    if (!factory) {
        g_print ("Failed to find factory of type 'filesink'\n");
        return -1;
    }
    element = gst_element_factory_create (factory, "encode_sink");
    if (!element) {
        g_print ("Failed to create element, even though its factory exists!\n");
        return -1;
    }
    GstData.app_sink = element;
*/
    GstData.app_sink = gst_element_factory_make ("appsink","video-sink");
#else
    GstData.app_source = gst_element_factory_make ("appsrc","video-source");
    GstData.app_sink = gst_element_factory_make ("appsink","video-sink");
#endif

    /* create vaapipostproc element */
    factory = gst_element_factory_find ("vaapipostproc");
    if (!factory) {
        g_print ("Failed to find factory of type 'vaapipostproc'\n");
        return -1;
    }
    element = gst_element_factory_create (factory, "video_convert");
    if (!element) {
        g_print ("Failed to create element, even though its factory exists!\n");
        return -1;
    }
    GstData.video_convert = element;
    

    /* create vaapih264enc element */
    factory = gst_element_factory_find ("vaapih264enc");
    if (!factory) {
        g_print ("Failed to find factory of type 'vaapih264enc'\n");
        return -1;
    }
    element = gst_element_factory_create (factory, "video-encoder");
    if (!element) {
        g_print ("Failed to create element, even though its factory exists!\n");
        return -1;
    }
    GstData.h264_encoder = element;

    
    if (!GstData.pipeline || !GstData.app_source || !GstData.h264_encoder ||
        !GstData.video_convert || !GstData.app_sink)
    {
        g_printerr ("One element could not be created... Exit\n");
        fclose(fp);
        free(g_rgb_buffer);
        return -1;
    }
    
    printf("============ link pipeline ==============\n");

    /* Configure appsrc */
#ifdef AUTO
    g_object_set(G_OBJECT(GstData.app_source), "display-name", ":0", NULL);
    g_object_set(G_OBJECT(GstData.app_source), "use-damage", FALSE, NULL);
    g_object_set(G_OBJECT(GstData.app_source), "startx", 0, NULL);
    g_object_set(G_OBJECT(GstData.app_source), "starty", 0, NULL);
    g_object_set(G_OBJECT(GstData.app_source), "endx", screen_width, NULL);
    g_object_set(G_OBJECT(GstData.app_source), "endy", screen_height, NULL);

    //g_object_set (G_OBJECT(GstData.app_sink), "location", output_file_name, NULL);
    /* Configure appsink */
    GstCaps *caps_app_sink;
    caps_app_sink = gst_caps_new_simple("video/x-h264", "stream-format", G_TYPE_STRING, "byte-stream",
                                        "alignment", G_TYPE_STRING, "au", NULL);
    g_object_set(G_OBJECT(GstData.app_sink), "emit-signals", TRUE, "caps", caps_app_sink, "sync", FALSE, NULL);
    g_signal_connect(GstData.app_sink, "new-sample", G_CALLBACK(new_h264_sample_on_appsink), &GstData);
    g_signal_connect(GstData.app_sink, "eos", G_CALLBACK(eos_on_appsink), &GstData);
#else
    char szTemp[64];
    int bits_per_pixel = 32;
    sprintf(szTemp, "%d", screen_width * screen_height * (bits_per_pixel >> 3));
    g_object_set(G_OBJECT(GstData.app_source), "blocksize", szTemp, NULL);
    g_object_set(G_OBJECT(GstData.app_source), "do-timestamp", TRUE, NULL);
    g_object_set(G_OBJECT(GstData.app_source), "stream-type", 0, "format", GST_FORMAT_TIME, NULL);
    g_object_set(G_OBJECT(GstData.app_source), "min-percent", 3, NULL);
    GstCaps *appsrc_caps;
    appsrc_caps = gst_caps_new_simple("video/x-raw", "format", G_TYPE_STRING,"BGRx",
                "width", G_TYPE_INT, screen_width,
                "height", G_TYPE_INT, screen_height,
                "framerate",GST_TYPE_FRACTION, frame_rate, 1, NULL);
    g_object_set(G_OBJECT(GstData.app_source), "caps", appsrc_caps, NULL);
    g_signal_connect(GstData.app_source, "need-data", G_CALLBACK(start_feed), &GstData);
    g_signal_connect(GstData.app_source, "enough-data", G_CALLBACK(stop_feed), &GstData);

    /* Configure appsink */
    GstCaps *caps_app_sink;
    caps_app_sink = gst_caps_new_simple("video/x-h264", "stream-format", G_TYPE_STRING, "byte-stream",
                                        "alignment", G_TYPE_STRING, "au", NULL);
    g_object_set(G_OBJECT(GstData.app_sink), "emit-signals", TRUE, "caps", caps_app_sink, "sync", FALSE, NULL);
    g_signal_connect(GstData.app_sink, "new-sample", G_CALLBACK(new_h264_sample_on_appsink), &GstData);
    g_signal_connect(GstData.app_sink, "eos", G_CALLBACK(eos_on_appsink), &GstData);
#endif

    /* Configure other elements */

    bus = gst_pipeline_get_bus(GST_PIPELINE(GstData.pipeline));
    bus_watch_id = gst_bus_add_watch(bus, (GstBusFunc)bus_msg_call, (gpointer)&GstData);
    gst_object_unref(bus);

    /* link elements*/
    gst_bin_add_many(GST_BIN(GstData.pipeline), GstData.app_source, GstData.video_convert,
            GstData.h264_encoder, GstData.app_sink, NULL);
#ifdef AUTO
    //if(gst_element_link(GstData.app_source,GstData.video_convert) != TRUE)
    if(f_link_elements_with_filter(GstData.app_source,GstData.video_convert) != TRUE)
#else
    if(gst_element_link_filtered(GstData.app_source, GstData.video_convert,appsrc_caps) != TRUE)
#endif
    {
        g_printerr ("GstData.app_source could not link GstData.video_convert\n");
        gst_object_unref (GstData.pipeline);
        free(g_rgb_buffer);
        fclose(fp);
        return -1;
    }
#ifdef AUTO
#else
    gst_caps_unref (appsrc_caps);
#endif

    if( rj_link_elements_with_filter(GstData.video_convert, GstData.h264_encoder) != TRUE)
    {
        g_printerr ("GstData.video_convert could not link GstData.h264_encoder\n");
        gst_object_unref (GstData.pipeline);
        free(g_rgb_buffer);
        fclose(fp);
        return -1;
    }

#if 0
    if(gst_element_link(GstData.h264_encoder, GstData.app_sink) != TRUE)
#else
    if(gst_element_link_filtered(GstData.h264_encoder, GstData.app_sink, caps_app_sink) != TRUE)
#endif
    {
        g_printerr ("GstData.h264_encoder could not link GstData.file_sink\n");
        gst_object_unref (GstData.pipeline);
        free(g_rgb_buffer);
        fclose(fp);
        return -1;
    }

#if 0
#else
    gst_caps_unref (caps_app_sink);
#endif

    
    GstData.app_src_index = 0;
    GstData.app_sink_index = 0;
    gst_element_set_state (GstData.pipeline, GST_STATE_PLAYING);
    g_print ("start GST_STATE_PLAYING\n");
    GstData.loop = g_main_loop_new(NULL, FALSE);    // Create gstreamer loop
    g_main_loop_run(GstData.loop);                  // Loop will run until receiving EOS (end-of-stream), will block here
    fprintf(stderr, "g_main_loop_run returned, stopping record\n");
    // Free resources
    gst_element_set_state (GstData.pipeline, GST_STATE_NULL);       // Stop pipeline to be released
    fprintf(stderr, "Deleting pipeline\n");
    gst_object_unref (GstData.pipeline);                            // THis will also delete all pipeline elements
    g_source_remove(bus_watch_id);
    g_main_loop_unref(GstData.loop);
    free(g_rgb_buffer);
    fclose(fp);
    return 0;
}
 
static void eos_on_appsink (GstElement *sink, GstDataStruct *pGstData)
{
    printf("appsink get signal eos !!!\n");
}
 
static void new_h264_sample_on_appsink (GstElement *sink, GstDataStruct *pGstData)
{
    GstSample *sample = NULL;
    g_signal_emit_by_name (sink, "pull-sample", &sample);
    if(sample)
    {
        pGstData->app_sink_index++;
        GstBuffer *buffer = gst_sample_get_buffer(sample);
        GstMapInfo info;
        if(gst_buffer_map((buffer), &info, GST_MAP_READ))
        {
          g_print ("h264 Streaming Buffer is Comming\n");
          // Here to get h264 buffer data with info.data and get h264 buffer size with info.size
          //gst_util_dump_mem (info.data, info.size);
          fwrite(info.data, info.size, 1, fp);
          g_print ("h264 Streaming Buffer is wrote, len:%d, index:%d\n", (int)info.size, pGstData->app_sink_index);
          gst_buffer_unmap(buffer, &info);
          gst_sample_unref (sample);
        }
    }
}



 /* This method is called by the idle GSource in the mainloop. We feed CHUNK_SIZE
  * bytes into appsrc.
  * The ide handler is added to the mainloop when appsrc requests us to start
  * sending data (need-data signal) and is removed when appsrc has enough data
  * (enough-data signal).
  */
//static int buf_size = screen_width * screen_height * 4
static gboolean read_data (GstDataStruct *pGstData)
{
    int data_size = screen_width * screen_height * 4;
#if 0 
     GstFlowReturn ret;
     GstMapInfo gst_map;
     GstBuffer    *gst_buffer   = NULL;
     int data_size = screen_width * screen_height * 4;
     pGstData->app_src_index++;
    if (pGstData->app_src_index > 500)
    {
        g_signal_emit_by_name (pGstData->app_source, "end-of-stream", &ret);
        //ret = gst_app_src_end_of_stream(GST_APP_SRC(pGstData->app_source));
        g_debug("eos returned %d at %d\n", ret, __LINE__);
        return FALSE;
    }
/*
    gst_buffer = gst_buffer_new();
    XImage * img;
    img = XGetImage(dsp,desktop,0,0,screen_width,screen_height,~0,ZPixmap);
    GST_BUFFER_MALLOCDATA(gst_buffer) = (unsigned char *)img->data;
    GST_BUFFER_SIZE(gst_buffer) = gst_buffer;
    GST_BUFFER_DATA(gst_buffer) = GST_BUFFER_MALLOCDATA(gst_buffer);
    g_signal_emit_by_name (pGstData->app_source, "push-buffer", gst_buffer, &ret);
    gst_buffer_unref (gst_buffer);
*/

     //需要时加线程锁、条件锁。

     gst_buffer = gst_buffer_new_allocate (NULL, data_size, NULL);

     gst_buffer_map (gst_buffer, &gst_map, GST_MAP_WRITE);

     XImage * img;
     img = XGetImage(dsp,desktop,0,0,screen_width,screen_height,~0,ZPixmap);
     g_rgb_buffer = (unsigned char *)img->data; 

     memcpy( (guchar *)gst_map.data, g_rgb_buffer, data_size);
     //gst_map.data = (guchar *)g_rgb_buffer;
     
     g_signal_emit_by_name (pGstData->app_source, "push-buffer", gst_buffer, &ret);
  
     gst_buffer_unmap (gst_buffer, &gst_map);
     gst_buffer_unref (gst_buffer);

     //释放线程锁、条件锁。

#else
    GstFlowReturn ret;
    GstBuffer *gst_buffer;
    //GstMemory *memory;

    XImage * img;
    img = XGetImage(dsp,desktop,0,0,screen_width,screen_height,~0,ZPixmap);

    //paint_mouse_pointer(img, dsp, screen_width, screen_height);
    //writeYuvFile((unsigned char *)img->data, (unsigned char *)g_rgb_buffer, screen_width, screen_height);
    //srcyuv_ptr = (unsigned char *) g_rgb_buffer;
 
    pGstData->app_src_index++;
    if (pGstData->app_src_index > 500)
    {
        g_signal_emit_by_name (pGstData->app_source, "end-of-stream", &ret);
        //ret = gst_app_src_end_of_stream(GST_APP_SRC(pGstData->app_source));
        g_debug("eos returned %d at %d\n", ret, __LINE__);
        return FALSE;
    }
    gst_buffer = gst_buffer_new_wrapped_full(GST_MEMORY_FLAG_READONLY,
            (guchar *)img->data, data_size, 0, data_size, NULL, NULL);

    
    //gst_buffer = gst_buffer_new();
    
    //memory = gst_memory_new_wrapped(GST_MEMORY_FLAG_READONLY, FbInfo.data, FbInfo.total_len, FbInfo.offset, FbInfo.real_len, NULL, NULL);
    //gst_buffer_append_memory (gst_buffer, memory);
    
    g_signal_emit_by_name (pGstData->app_source, "push-buffer", gst_buffer, &ret);
 
    //GST_DEBUG ("feed buffer %p, offset %" G_GUINT64_FORMAT "-%u", buffer,FbInfo.offset, FbInfo.real_len);
    gst_buffer_unref(gst_buffer);
#endif
    if (ret != GST_FLOW_OK)
    {
        g_debug("push buffer returned %d for %d bytes \n", ret, data_size);
        return FALSE;
    }
    return TRUE;
}
 
static void start_feed (GstElement * pipeline, guint size, GstDataStruct *pGstData)
{
    g_print("start feed...................\n");
    if (pGstData->sourceid == 0) {
        //GST_DEBUG ("start feeding");
        pGstData->sourceid = g_idle_add ((GSourceFunc) read_data, pGstData);
    }
}
 
static void stop_feed (GstElement * pipeline, GstDataStruct *pGstData)
{
    g_print("stop feed...................\n");
    if (pGstData->sourceid != 0) {
        //GST_DEBUG ("stop feeding");
        g_source_remove (pGstData->sourceid);
        pGstData->sourceid = 0;
    }
}
 
// Bus messages processing, similar to all gstreamer examples
gboolean bus_msg_call(GstBus *bus, GstMessage *msg, GstDataStruct *pGstData)
{
    gchar *debug;
    GError *error;
    GMainLoop *loop = pGstData->loop;
    GST_DEBUG ("got message %s",gst_message_type_get_name (GST_MESSAGE_TYPE (msg)));
    switch (GST_MESSAGE_TYPE(msg))
    {
        case GST_MESSAGE_EOS:
            fprintf(stderr, "End of stream\n");
            g_main_loop_quit(loop);
            break;
        case GST_MESSAGE_ERROR:
            gst_message_parse_error(msg, &error, &debug);
            g_free(debug);
            g_printerr("Error: %s\n", error->message);
            g_error_free(error);
            g_main_loop_quit(loop);
            break;
        default:
            break;
    }
    return TRUE;
}


/* use to link vaapipostproc and vaapih264enc element*/
static gboolean
rj_link_elements_with_filter (GstElement *element1, GstElement *element2)
{
  gboolean link_ok;
  GstCaps *caps;
  
  caps = gst_caps_new_simple ("video/x-raw",
        "format", G_TYPE_STRING,"NV12",
        "width", G_TYPE_INT, screen_width,
        "height", G_TYPE_INT, screen_height,
        "framerate", GST_TYPE_FRACTION, frame_rate, 1,
        NULL);

  link_ok = gst_element_link_filtered (element1, element2, caps);
  gst_caps_unref (caps);

  if (!link_ok) {
    g_warning ("Failed to link element1 and element2!");
  }
  
  return link_ok;
}


/* the x11 init function*/
static int xDispalyInit()
{
    dsp = XOpenDisplay(":0");/* Connect to a local display */
    if (NULL==dsp) {
        //sprintf(err_str,"Error:Cannot connect to local display\n");
        printf("Error:Cannot connect to local display\n");
        return -1;
    }
    desktop = RootWindow(dsp,0);/* Refer to the root window */
    if (0==desktop) {
        printf("cannot get root window\n");
        return -1;
    }
    
    /* Retrive the width and the height of the screen */
    screen_width = DisplayWidth(dsp,0);
    screen_height = DisplayHeight(dsp,0);
    return 0;
}

